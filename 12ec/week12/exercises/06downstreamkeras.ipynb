{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "This notebook illustrates how we can use embeddings in Machine Learning tasks.\n",
    "\n",
    "As always, we first import neccesary modules. We also get our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install embeddingvectorizer    # you need to install this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Supervised text classification\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding, LSTM, GlobalMaxPooling1D\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "import re\n",
    "# word embedding stuff\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# data\n",
    "from courseutils import get_review_data\n",
    "\n",
    "# lets get more output\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to have gensim 4.0 or higher - there are quite some extensive syntax changes, see links below\n",
    "# (older version of this notebook was for gensim 3 -- hope I migrated everything correctly...)\n",
    "# https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\n",
    "# https://github.com/RaRe-Technologies/gensim/wiki/Using-Gensim-Embeddings-with-Keras-and-Tensorflow\n",
    "print(gensim.__version__)\n",
    "assert gensim.__version__[0] =='4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached file reviewdata.pickle.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:43:53,090 : INFO : loading projection weights from /home/damian/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "2021-04-29 19:44:56,674 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (400000, 300) matrix of type float32 from /home/damian/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-04-29T19:44:56.666398', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.29', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "reviews_train, reviews_test, y_train, y_test = get_review_data()\n",
    "\n",
    "reviews_train, y_train = shuffle(reviews_train, y_train, random_state=42)\n",
    "reviews_test, y_test = shuffle(reviews_test, y_test, random_state=42)\n",
    "\n",
    "# get word embedding model\n",
    "\n",
    "# pretrained:\n",
    "# wv = api.load('word2vec-google-news-300')\n",
    "wv = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "# or our own:\n",
    "#wv = gensim.models.Word2Vec.load(\"mymodel\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext-wiki-news-subwords-300',\n",
       " 'conceptnet-numberbatch-17-06-300',\n",
       " 'word2vec-ruscorpora-300',\n",
       " 'word2vec-google-news-300',\n",
       " 'glove-wiki-gigaword-50',\n",
       " 'glove-wiki-gigaword-100',\n",
       " 'glove-wiki-gigaword-200',\n",
       " 'glove-wiki-gigaword-300',\n",
       " 'glove-twitter-25',\n",
       " 'glove-twitter-50',\n",
       " 'glove-twitter-100',\n",
       " 'glove-twitter-200',\n",
       " '__testing_word2vec-matrix-synopsis']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.info(name_only=True)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_train) == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dumb is as dumb does, in this thoroughly uninteresting, supposed black comedy. Essentially what starts out as Chris Klein trying to maintain a low profile, eventually morphs into an uninspired version of \"The Three Amigos\", only without any laughs. In order for black comedy to work, it must be outrageous, which \"Play Dead\" is not. In order for black comedy to work, it cannot be mean spirited, which \"Play Dead\" is. What \"Play Dead\" really is, is a town full of nut jobs. Fred Dunst does however do a pretty fair imitation of Billy Bob Thornton\\'s character from \"A Simple Plan\", while Jake Busey does a pretty fair imitation of, well, Jake Busey. - MERK',\n",
       " \"I dug out from my garage some old musicals and this is another one of my favorites. It was written by Jay Alan Lerner and directed by Vincent Minelli. It won two Academy Awards for Best Picture of 1951 and Best Screenplay. The story of an American painter in Paris who tries to make it big. Nina Foch is a sophisticated lady of means and is very interested in helping him, but soon finds she loves the guy. Meanwhile Gene Kelly falls for lovely damsel, Leslie Caron. His main dancing partner, and I must say they are fantastic together on the floor and otherwise. Famous French singer Georges Guietary sings, too. So if you like good smooth dancing and fun filled scenes filled with Oscar Levant's nimble piano fingers, the songs of George Gershwyn will live on forever in this colorful gem. 8/10\",\n",
       " 'After watching this movie I was honestly disappointed - not because of the actors, story or directing - I was disappointed by this film advertisements.<br /><br />The trailers were suggesting that the battalion \"have chosen the third way out\" other than surrender or die (Polish infos were even misguiding that they had the choice between being killed by own artillery or German guns, they even translated the title wrong as \"misplaced battalion\"). This have tickled the right spot and I bought the movie.<br /><br />The disappointment started when I realized that the third way is to just sit down and count dead bodies followed by sitting down and counting dead bodies... Then I began to think \"hey, this story can\\'t be that simple... I bet this clever officer will find some cunning way to save what left of his troops\". Well, he didn\\'t, they were just sitting and waiting for something to happen. And so was I.<br /><br />The story was based on real events of World War I, so the writers couldn\\'t make much use of their imagination, but even thought I found this movie really unchallenging and even a little bit boring. And as I wrote in the first place - it isn\\'t fault of actors, writers or director - their marketing people have raised my expectations high above the level that this movie could cope with.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "## A simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE = 2500\n",
    "np.random.seed(666)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeY(Y):\n",
    "    '''create one-hot (dummies) for output, see also https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "    encode class values as integers\n",
    "    '''\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    encoded_Y = encoder.transform(Y)\n",
    "    dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "    return dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodeY(['aa','bb','aa','cc','aa','cc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(reviews_train)\n",
    "X_test = vectorizer.transform(reviews_test)\n",
    "X_test.sort_indices()\n",
    "X_train.sort_indices()\n",
    "\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "y_train_int = encodeY(y_train)[:,0]\n",
    "y_test_int = encodeY(y_test)[:,0]\n",
    "\n",
    "numberoflabels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74538"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               22361700  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 22,362,001\n",
      "Trainable params: 22,362,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=input_dim, activation='relu'))\n",
    "#model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "           optimizer='adam', \n",
    "            metrics=['accuracy', Precision(), Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "704/704 [==============================] - 63s 89ms/step - loss: 0.3880 - accuracy: 0.8328 - precision: 0.8317 - recall: 0.8426 - val_loss: 0.2673 - val_accuracy: 0.8904 - val_precision: 0.8946 - val_recall: 0.8845\n",
      "Epoch 2/5\n",
      "704/704 [==============================] - 63s 90ms/step - loss: 0.0855 - accuracy: 0.9706 - precision: 0.9705 - recall: 0.9708 - val_loss: 0.3811 - val_accuracy: 0.8788 - val_precision: 0.8776 - val_recall: 0.8797\n",
      "Epoch 3/5\n",
      "704/704 [==============================] - 66s 94ms/step - loss: 0.0200 - accuracy: 0.9939 - precision: 0.9938 - recall: 0.9941 - val_loss: 0.5015 - val_accuracy: 0.8800 - val_precision: 0.8828 - val_recall: 0.8757\n",
      "Epoch 4/5\n",
      "704/704 [==============================] - 60s 86ms/step - loss: 0.0043 - accuracy: 0.9995 - precision: 0.9993 - recall: 0.9998 - val_loss: 0.6406 - val_accuracy: 0.8776 - val_precision: 0.8719 - val_recall: 0.8845\n",
      "Epoch 5/5\n",
      "704/704 [==============================] - 66s 94ms/step - loss: 0.0015 - accuracy: 0.9996 - precision: 0.9993 - recall: 0.9999 - val_loss: 0.7111 - val_accuracy: 0.8824 - val_precision: 0.8922 - val_recall: 0.8693\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.8810 - accuracy: 0.8515 - precision: 0.8525 - recall: 0.8502\n",
      "Accuracy: 0.85, Precision: 0.85, Recall: 0.85\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train[:-VALIDATION_SIZE], y_train_int[:-VALIDATION_SIZE],\n",
    "                     epochs=5,\n",
    "                     verbose=True,\n",
    "                     validation_data=(X_train[-VALIDATION_SIZE:], y_train_int[-VALIDATION_SIZE:]))\n",
    "\n",
    "_, acc, precision, recall = model.evaluate(X_test, y_test_int)\n",
    "print(f\"Accuracy: {acc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A model with a second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 300)               22361700  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 22,542,601\n",
      "Trainable params: 22,542,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "704/704 [==============================] - 60s 83ms/step - loss: 0.3887 - accuracy: 0.8294 - precision_1: 0.8277 - recall_1: 0.8429 - val_loss: 0.2678 - val_accuracy: 0.8856 - val_precision_1: 0.8810 - val_recall_1: 0.8909\n",
      "Epoch 2/5\n",
      "704/704 [==============================] - 58s 83ms/step - loss: 0.0794 - accuracy: 0.9735 - precision_1: 0.9753 - recall_1: 0.9714 - val_loss: 0.4533 - val_accuracy: 0.8820 - val_precision_1: 0.8778 - val_recall_1: 0.8869\n",
      "Epoch 3/5\n",
      "704/704 [==============================] - 58s 83ms/step - loss: 0.0168 - accuracy: 0.9942 - precision_1: 0.9941 - recall_1: 0.9942 - val_loss: 0.7970 - val_accuracy: 0.8744 - val_precision_1: 0.8802 - val_recall_1: 0.8661\n",
      "Epoch 4/5\n",
      "704/704 [==============================] - 58s 83ms/step - loss: 0.0091 - accuracy: 0.9973 - precision_1: 0.9968 - recall_1: 0.9979 - val_loss: 0.8756 - val_accuracy: 0.8684 - val_precision_1: 0.8614 - val_recall_1: 0.8773\n",
      "Epoch 5/5\n",
      "704/704 [==============================] - 59s 83ms/step - loss: 0.0055 - accuracy: 0.9981 - precision_1: 0.9983 - recall_1: 0.9978 - val_loss: 1.0272 - val_accuracy: 0.8804 - val_precision_1: 0.8898 - val_recall_1: 0.8677\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.3147 - accuracy: 0.8484 - precision_1: 0.8396 - recall_1: 0.8614\n",
      "Accuracy: 0.85, Precision: 0.84, Recall: 0.86\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "           optimizer='adam', \n",
    "            metrics=['accuracy', Precision(), Recall()])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train[:-VALIDATION_SIZE], y_train_int[:-VALIDATION_SIZE],\n",
    "                     epochs=5,\n",
    "                     verbose=True,\n",
    "                     validation_data=(X_train[-VALIDATION_SIZE:], y_train_int[-VALIDATION_SIZE:]))\n",
    "\n",
    "_, acc, precision, recall = model.evaluate(X_test, y_test_int)\n",
    "print(f\"Accuracy: {acc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 300)               22361700  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 22,723,201\n",
      "Trainable params: 22,723,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "704/704 [==============================] - 60s 85ms/step - loss: 0.3949 - accuracy: 0.8251 - precision_2: 0.8198 - recall_2: 0.8383 - val_loss: 0.2790 - val_accuracy: 0.8728 - val_precision_2: 0.9453 - val_recall_2: 0.7907\n",
      "Epoch 2/5\n",
      "704/704 [==============================] - 59s 84ms/step - loss: 0.0842 - accuracy: 0.9689 - precision_2: 0.9704 - recall_2: 0.9678 - val_loss: 0.3352 - val_accuracy: 0.8848 - val_precision_2: 0.8908 - val_recall_2: 0.8765\n",
      "Epoch 3/5\n",
      "704/704 [==============================] - 59s 84ms/step - loss: 0.0154 - accuracy: 0.9957 - precision_2: 0.9951 - recall_2: 0.9964 - val_loss: 0.7701 - val_accuracy: 0.8852 - val_precision_2: 0.8852 - val_recall_2: 0.8845\n",
      "Epoch 4/5\n",
      "704/704 [==============================] - 59s 84ms/step - loss: 0.0068 - accuracy: 0.9978 - precision_2: 0.9972 - recall_2: 0.9983 - val_loss: 0.8719 - val_accuracy: 0.8704 - val_precision_2: 0.9285 - val_recall_2: 0.8019\n",
      "Epoch 5/5\n",
      "704/704 [==============================] - 60s 85ms/step - loss: 0.0075 - accuracy: 0.9979 - precision_2: 0.9977 - recall_2: 0.9980 - val_loss: 1.1725 - val_accuracy: 0.8768 - val_precision_2: 0.8560 - val_recall_2: 0.9054\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.6143 - accuracy: 0.8399 - precision_2: 0.8073 - recall_2: 0.8930\n",
      "Accuracy: 0.84, Precision: 0.81, Recall: 0.89\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "           optimizer='adam', \n",
    "            metrics=['accuracy', Precision(), Recall()])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train[:-VALIDATION_SIZE], y_train_int[:-VALIDATION_SIZE],\n",
    "                     epochs=5,\n",
    "                     verbose=True,\n",
    "                     validation_data=(X_train[-VALIDATION_SIZE:], y_train_int[-VALIDATION_SIZE:]))\n",
    "\n",
    "_, acc, precision, recall = model.evaluate(X_test, y_test_int)\n",
    "print(f\"Accuracy: {acc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "embedding_dim = 300\n",
    "\n",
    "# Tokenize words\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(reviews_train)\n",
    "X_train = tokenizer.texts_to_sequences(reviews_train)\n",
    "X_test = tokenizer.texts_to_sequences(reviews_test)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad sequences with zeros\n",
    "maxlen = len(max(X_train, key=len)) # never truncate -- alternatively, set max length to lower value \n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1973, 300)         26574900  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1969, 300)         450300    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 27,115,801\n",
      "Trainable params: 27,115,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(Conv1D(embedding_dim, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',  Precision(), Recall()])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "704/704 [==============================] - 1255s 2s/step - loss: 0.4743 - accuracy: 0.7399 - precision_3: 0.7491 - recall_3: 0.7214 - val_loss: 0.2497 - val_accuracy: 0.8992 - val_precision_3: 0.8806 - val_recall_3: 0.9230\n",
      "Epoch 2/3\n",
      "704/704 [==============================] - 1254s 2s/step - loss: 0.1337 - accuracy: 0.9519 - precision_3: 0.9513 - recall_3: 0.9508 - val_loss: 0.2723 - val_accuracy: 0.8896 - val_precision_3: 0.8572 - val_recall_3: 0.9342\n",
      "Epoch 3/3\n",
      "704/704 [==============================] - 1327s 2s/step - loss: 0.0364 - accuracy: 0.9894 - precision_3: 0.9879 - recall_3: 0.9910 - val_loss: 0.2806 - val_accuracy: 0.9092 - val_precision_3: 0.9208 - val_recall_3: 0.8949\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train[:-VALIDATION_SIZE], y_train_int[:-VALIDATION_SIZE], \n",
    "          epochs=3, verbose=True,\n",
    "          validation_data=(X_train[-VALIDATION_SIZE:], y_train_int[-VALIDATION_SIZE:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 373s 477ms/step - loss: 0.3209 - accuracy: 0.8963 - precision_3: 0.8981 - recall_3: 0.8940\n",
      "Accuracy: 0.90, Precision: 0.90, Recall: 0.89\n"
     ]
    }
   ],
   "source": [
    "_, acc, precision, recall = model.evaluate(X_test, y_test_int)\n",
    "print(f\"Accuracy: {acc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def gensim_to_keras_embedding(wv, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = wv  # structure holding the result of training\n",
    "    weights = wv.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = wv.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = gensim_to_keras_embedding(wv, train_embeddings=True)\n",
    "input_dim = (len(X_train[:-VALIDATION_SIZE]), 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 300)         120000000 \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 300)         450300    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 120,540,901\n",
      "Trainable params: 120,540,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(embedding_dim, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',  Precision(), Recall()])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "704/704 [==============================] - 2256s 3s/step - loss: 0.3684 - accuracy: 0.8322 - precision_5: 0.8390 - recall_5: 0.8222 - val_loss: 0.2792 - val_accuracy: 0.8824 - val_precision_5: 0.8846 - val_recall_5: 0.8789\n",
      "Epoch 2/3\n",
      "704/704 [==============================] - 2211s 3s/step - loss: 0.1562 - accuracy: 0.9430 - precision_5: 0.9431 - recall_5: 0.9429 - val_loss: 0.2957 - val_accuracy: 0.8836 - val_precision_5: 0.8551 - val_recall_5: 0.9230\n",
      "Epoch 3/3\n",
      "704/704 [==============================] - 2109s 3s/step - loss: 0.0519 - accuracy: 0.9828 - precision_5: 0.9833 - recall_5: 0.9824 - val_loss: 0.3735 - val_accuracy: 0.8900 - val_precision_5: 0.8977 - val_recall_5: 0.8797\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train[:-VALIDATION_SIZE], y_train_int[:-VALIDATION_SIZE], \n",
    "          epochs=3, verbose=True,\n",
    "          validation_data=(X_train[-VALIDATION_SIZE:], y_train_int[-VALIDATION_SIZE:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 448s 573ms/step - loss: 0.3731 - accuracy: 0.8848 - precision_5: 0.8941 - recall_5: 0.8730\n",
      "Accuracy: 0.88, Precision: 0.89, Recall: 0.87\n"
     ]
    }
   ],
   "source": [
    "_, acc, precision, recall = model.evaluate(X_test, y_test_int)\n",
    "print(f\"Accuracy: {acc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too much memory requirements below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(35))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',  Precision(), Recall()])\n",
    "print(model.summary())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "More examples: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Recall(), Precision()])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train[:-VALIDATION_SIZE], y_train_int[:-VALIDATION_SIZE], \n",
    "          epochs=3, batch_size=128, verbose=1, \n",
    "          validation_data=(X_train[-VALIDATION_SIZE:], y_train_int[-VALIDATION_SIZE:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc, precision, recall = model.evaluate(X_test, y_test_int)\n",
    "print(f\"Accuracy: {acc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "history = model.fit(X_train[:-VALIDATION_SIZE], y_train_int[:-VALIDATION_SIZE], \n",
    "          epochs=5, verbose=True,\n",
    "          validation_data=(X_train[-VALIDATION_SIZE:], y_train_int[-VALIDATION_SIZE:]))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
